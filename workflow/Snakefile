# A Snakemake pipeline for quality control of Illumina next-generation
#                            sequencing data
# *********************************************************************

from pathlib import Path
import pandas as pd


# *********************************************************************
# configuration file
configfile: "config/config.yaml"


# global wild cards of sample and pairpair list
(samples,) = glob_wildcards(Path(config["input_dir"], "{sample}_1.fq.gz"))


localrules: all, multiqc

# all output
# *********************************************************************
rule all:
    input:
        # multiqc output depends on fastqc output, see multiqc rule
        "results/multiqc_report.html",
        # no assembly for now
        #expand("results/05_metaspades/{sample}/contigs.fasta", sample = samples)
	expand("results/06_genomescope/{sample}/summary.txt", sample = samples),
        # KrakenUniq installation
        Path(config["krakenuniq"]["database_path"], '.done'),
        #expand("results/05_krakenuniq/{sample}.krakenuniq.report.txt", sample = samples)

# seqkit stats - simple statistics overview
# ********************************************************************
rule seqkit_stats:
    input:
        fastx = expand(Path(config["input_dir"], "{sample}_{r}.fq.gz"), sample = samples, r = [ 1, 2 ])
    output:
        stats = "doc/stats.tsv"
    log:
        "logs/stats.log"
    params:
        command = "stats",
        extra = "--all --tabular"
    threads: 20
    wrapper:
        "v3.0.2/bio/seqkit"


# fastqc - check quality of raw fastq-files and merge fastqc reports
# *********************************************************************
rule fastqc:
    input:
        Path(config["input_dir"], "{sample}_{r}.fq.gz")
    output:
        html = "results/01_fastqc/{sample}_{r}.html",
        zip  = "results/01_fastqc/{sample}_{r}_fastqc.zip" # the suffix _fastqc.zip is necessary for multiqc to find the file. If not using multiqc, you are free to choose an arbitrary filename
    params:
        extra = "--quiet"
    log:
        "logs/fastqc/{sample}_{r}.log"
    threads: 2
    resources:
        mem_mb = 1024
    wrapper:
        "v3.0.2/bio/fastqc"

# fastp - all-in-one fastq preprocessor
# ********************************************************************
rule fastp:
    input:
        sample = [ Path(config["input_dir"], "{sample}_1.fq.gz"), Path(config["input_dir"], "{sample}_2.fq.gz") ]
    output:
        trimmed = ["results/02_fastp/trimmed/{sample}_1.fq.gz", "results/02_fastp/trimmed/{sample}_2.fq.gz"],
        # Unpaired reads separately
        unpaired1 = "results/02_fastp/trimmed/{sample}.u1.fq.gz",
        unpaired2 = "results/02_fastp/trimmed/{sample}.u2.fq.gz",
        # or in a single file
	# unpaired="trimmed/pe/{sample}.singletons.fastq",
        merged = "results/02_fastp/trimmed/{sample}.merged.fq.gz",
        failed = "results/02_fastp/trimmed/{sample}.failed.fq.gz",
        html = "results/02_fastp/report/{sample}.fastp.html",
        json = "results/02_fastp/report/{sample}.fastp.json"
    log:
        "logs/fastp/{sample}.log"
    threads:
        3
    params:
        adapters = "--adapter_sequence " + config["adapters"]["novogene_r1"] + " --adapter_sequence_r2 " + config["adapters"]["novogene_r2"],
        extra = "--merge"
    threads: 2
    wrapper:
        "v3.0.2/bio/fastp"

# cutadapt - adapter and quality trimmer and filterer
# *********************************************************************
rule cutadapt:
    input:
        [ Path(config["input_dir"], "{sample}_1.fq.gz"), Path(config["input_dir"], "{sample}_2.fq.gz") ],
    output:
        fastq1 = "results/03_cutadapt/trimmed/{sample}_1.fq.gz",
        fastq2 = "results/03_cutadapt/trimmed/{sample}_2.fq.gz",
        qc = "results/03_cutadapt/trimmed/{sample}.qc.txt",
    params:
        adapters='-a {universal_r1} -a {additional_r1} -A {universal_r2} -A {additional_r2}'.format(
            tprime = config["adapters"]["novogene_r2"],
	    fprime = config["adapters"]["novogene_r1"],
	    universal_r1 = config["adapters"]["universal_r1"],
	    universal_r2 = config["adapters"]["universal_r2"],
	    additional_r1 = config["adapters"]["additional_r1"],
	    additional_r2 = config["adapters"]["additional_r2"],
	    ),
        extra="--minimum-length 10 -q 20 --poly-a --times 3",
    log:
        "logs/cutadapt/{sample}.log",
    threads: 4  # set desired number of threads here
    wrapper:
        "v3.0.2/bio/cutadapt/pe"

# fastqc round 2
#**********************************************************************
rule fastqc_trimmed:
    input:
        "results/03_cutadapt/trimmed/{sample}_{r}.fq.gz"
    output:
        html = "results/04_fastqc/{sample}_{r}.html",
        zip  = "results/04_fastqc/{sample}_{r}_fastqc.zip" # the suffix _fastqc.zip is necessary for multiqc to find the file. If not using multiqc, you are free to choose an arbitrary filename
    params:
        extra = "--quiet"
    log:
        "logs/fastqc/{sample}_{r}.log"
    threads: 2
    resources:
        mem_mb = 1024
    wrapper:
        "v3.0.2/bio/fastqc"


# MetaSPADES to assemble contigs
# *********************************************************************
rule run_metaspades:
    input:
        reads = ["results/03_cutadapt/trimmed/{sample}_1.fq.gz", "results/03_cutadapt/trimmed/{sample}_2.fq.gz"],
    output:
        contigs = "results/05_metaspades/{sample}/contigs.fasta",
        scaffolds = "results/05_metaspades/{sample}/scaffolds.fasta",
        dir = directory("results/05_metaspades/{sample}/intermediate_files"),
    benchmark:
        "logs/benchmarks/assembly/spades.{sample}.txt"
    params:
        # all parameters are optional
        k = "auto",
        extra = "--only-assembler",
    log:
        "log/spades.{sample}.log",
    threads: 8
    resources:
        mem_mem = 250000,
        time = 60 * 24,
    wrapper:
        "v3.0.2/bio/spades/metaspades"


# multiqc - merge fastqc reports
# *********************************************************************
rule multiqc:
    input:
        expand("results/03_cutadapt/trimmed/{sample}.qc.txt", sample = samples),
        expand("results/04_fastqc/{sample}_{r}_fastqc.zip", sample = samples, r = ["1", "2"]),
    output:
        "results/multiqc_report.html",
        directory("results/multiqc_data")
    params:
        extra = "--data-dir"
    wrapper:
        "v3.0.2/bio/multiqc"

# install KrakenUniq and its database
# ***********************************************************************
rule install_krakenuniq:
    output:
        Path(config["krakenuniq"]["database_path"], '.done')
    conda:
        "envs/krakenuniq.yaml"
    params:
        min_seq_len = config["krakenuniq"]["min_seq_len"],
        databases = lambda wildcards: config["krakenuniq"]["databases"]
    shell:
        """
        mkdir -p $(dirname {output})
        krakenuniq-download -o {output} --rsync --verbose --min-seq-len {params.min_seq_len} {params.databases}
        touch {output}
        """

# run KrakenUniq
# *************************************************************************
rule krakenuniq:
    input:
        db = config["krakenuniq"]["database_path"],
        fq = ["results/03_cutadapt/trimmed/{sample}_1.fq.gz", "results/03_cutadapt/trimmed/{sample}_2.fq.gz"]
    output:
        report = "results/05_krakenuniq/{sample}.krakenuniq.report.txt",
        tsv = "results/05_krakenuniq/{sample}.krakenuniq.tsv",
        unclassified = "results/05_krakenuniq/{sample}.krakenuniq.unclassified.txt",
        classified = "results/05_krakenuniq/{sample}.krakenuniq.classified.txt",
    conda:
        "envs/krakenuniq.yaml"
    threads:
        16
    params:
        extra = "--fastq-input --gzip-compressed --paired"
    shell:
        """
        krakenuniq --threads {threads} --db {input.db} {params.extra} --report-file {output.report} --unclassified-out {output.unclassified} --classified-out {output.classified} {input.fq} > {output.tsv}
        """

# run Jellyfish to count and histogram k-mers
#**************************************************************************
rule jellyfish_count:
    input:
        [ "results/03_cutadapt/trimmed/{sample}_1.fq.gz", "results/03_cutadapt/trimmed/{sample}_2.fq.gz" ]
    output:
        "results/05_jellyfish/{sample}.jf",
    log:
        "logs/jellyfish/{sample}.jf.log",
    params:
        kmer_length=21,
        size="1G",
        extra="--canonical",
    threads: 2
    wrapper:
        "file:workflow/wrappers/jellyfish_count"

rule jellyfish_histo:
    input:
        "results/05_jellyfish/{sample}.jf",
    output:
        "results/05_jellyfish/{sample}.histo",
    log:
        "logs/jellyfish/{sample}.histo.log",
    threads: 2
    wrapper:
        "v3.3.3/bio/jellyfish/histo"

# run GenomeScope
# *************************************************************************
rule genomescope:
    input:
        hist="results/05_jellyfish/{sample}.histo",
    output:
        multiext(
            "results/06_genomescope/{sample}/",
            "linear_plot.png",
            "log_plot.png",
            "model.txt",
            "progress.txt",
            "SIMULATED_testing.tsv",
            "summary.txt",
            "transformed_linear_plot.png",
            "transformed_log_plot.png",
        ),
    log:
        "logs/genomescope/{sample}.log",
    params:
        extra="--kmer_length 32 --testing",
    wrapper:
        "v3.3.3/bio/genomescope"
